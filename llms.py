import json
from search_indexing import search_faiss_index, download_and_index_documents
from openai_utils import load_openai_api_key, query_chat_openai
import streamlit as st

COT_BREAKDOWN_PROBLEM_SYSTEM_MESSAGE = """You are an expert in breaking down a big problem into smaller problems. The reason you break down big problems into smaller ones, is that the system can then search for solutions for each one of the small problems individually, thus increasing the chance of success.

If two or more of the small problems are related, please merge them into just one small problem.

Example:

I need a Cisco switch that supports the following requirements:

Support stacking
support stacking using different models
support 48 ports
support PoE

Can be broken down as:

- Cisco switch that support stacking and mixed stacking
- Cisco switch that has 48 ports with PoE
"""

COT_BRAINSTORM_SIMPLE_PROBLEM_SYSTEM_MESSAGE = """You are an AI that is part of a larger brainstorming group, tasked with finding a solution to a bigger problem.
This bigger problem has been broken down, and each of these smaller problems will be given to a different AI, including you.
Your task is to simulate 3 experts that will be given this smaller problem plus a small collection of snippets extracted from technical documents, and will work together a solution.
You are supposed to deduce your observations and solutions ONLY out of the provided snippets. If the snippets don't provide enough information, don't assume or make stuff up.
You will also receive a summarized version of the other smaller problems and the solutions proposed to them. Take that information into account when brainstorming the problem you were given to resolve.
The flow is: expert 1 will generate an observation about the problem. Then expert 2 will take expert 1's observation plus what has been discussed so far, and generate a new observation. This observation generated by expert 2 will then be used by expert 3 to generate his own observation. At the end, I want you to take all this discussion and generate a final solution to the problem."""

COT_GENERATE_BIG_SOLUTION_SYSTEM_MESSAGE = f"""You are an expert that will be given a problem, and a list of observations and potential solutions to this problem. The problem may have different requirements, and each solution in the list is accounting for one of these requirements.
It's your job to take all these solutions together, and come up with a final solution that should meet all the requirements of the original problem"""


class BrainstormProblemSolving:
    """
    Attempt to solve a complex problem by using a multi-step brainstorming approach.
    The workflow used is:
        - First the problem is broken down into smaller problems (done using a LLM)
        - Then, for each small problem, emulate a brainstorming session with 3 experts, that will together work in finding
        a solution. At this step, relevant snippets are provided to the experts using RAG; plus, the solutions found for
        each small problem is also provided, to give a full context to the experts
        - At the end, all small problems and their respective solutions are compiled into one "big" solution
    """

    def __init__(self, problem: str):

        self.problem = problem
        self.small_problems = list()
        self.solutions = list()
        self.index = None
        self.all_snippets = list()
        load_openai_api_key()

    def break_down_problem(self) -> list[str]:
        """
        Break down the provided problem into a list of small problems
        """

        system_message = COT_BREAKDOWN_PROBLEM_SYSTEM_MESSAGE

        # Instruct the LLM to break down the problem, and return the results as a JSON object
        prompt = f"""Problem to be broken down:
{self.problem}

<End of Problem>

Please return your results as a JSON object, in this format:

{{\"results\": [\"problem_1\", \"problem_2\", ...]}}
"""
        response = query_chat_openai(system_message, prompt)

        # Parse LLM response as a JSON object
        try:
            response = json.loads(response)
        except json.decoder.JSONDecodeError:
            if '{"results"' in response:
                split_response = response.split('{')[1]
                response = json.loads(f"{{{split_response}")
            else:
                raise Exception('Error breaking down problem: Response from LLM is not JSON compliant')

        self.small_problems = response['results']
        return self.small_problems

    def brainstorm_simple_problem(self, simple_problem: str, snippets: list[str], other_problems_and_solutions: list[str]):
        """
        Search for a solution to a problem, by simulating 3 experts that together brainstorm the solution. Relevant snippets
        and the other small problems and solutions are also provided to the LLM, in order to help give it the full context.
        """

        system_message = COT_BRAINSTORM_SIMPLE_PROBLEM_SYSTEM_MESSAGE

        snippets_text = str()
        for idx, snippet in enumerate(snippets):
            snippet_text = f"<SNIPPET_{idx + 1}\n\n{snippet}\n\n<END_SNIPPET_{idx + 1}"
            snippets_text += snippet_text

        joined_other_problems_and_solutions = '\n\n'.join(other_problems_and_solutions)
        prompt = f"""The problem is: {simple_problem}
The snippets to use are:    
{snippets_text}

The other smaller problems and their solutions are:

{joined_other_problems_and_solutions if joined_other_problems_and_solutions else ""}
"""

        response = query_chat_openai(system_message, prompt)
        system_message = f"""You will be given observations made by 3 experts that were working together to resolve a problem. Your task is to summarize their findings in just one concise response."""
        summarized_response = query_chat_openai(system_message, response)

        return summarized_response

    def brainstorm_all_problems(self):
        """
        Brainstorm all small problems, one at the time. Each problem and solution found are added to the following queries,
        in order to help the LLM get a full context of the problem
        """

        assert self.index is not None, 'Search index not built'
        assert self.small_problems, 'List of small problems is empty. Please call self.break_down_problem first'

        problems_so_far = list()
        for small_problem in self.small_problems:
            st.write(f'Brainstorming the following small problem: {small_problem}')

            snippets = search_faiss_index(self.index, small_problem)
            # Append snippets to global snippets list
            for snippet in snippets:
                if snippet not in self.all_snippets:
                    self.all_snippets.append(snippet)

            solution = self.brainstorm_simple_problem(small_problem, snippets, problems_so_far)
            problem_and_solution = f"Problem: {small_problem}\n\nProposed solution: {solution}"
            problems_so_far.append(problem_and_solution)
            self.solutions.append(solution)

        return self.solutions

    def summarize_solution(self) -> str:
        """
        Given a list of solutions for the small problems, and the original "big" problem provided by the user, generate
        a summarized solution
        """

        system_message = COT_GENERATE_BIG_SOLUTION_SYSTEM_MESSAGE

        joined_solutions = '\n\n'.join(self.solutions)

        prompt = f"""Problem: {self.problem}
Solutions: {joined_solutions}

Summarized solution:"""

        response = query_chat_openai(system_message, prompt)

        return response

    def search_for_solution(self, urls: list[str]) -> str:
        """
        Run entire pipeline (original problem -> break it down into smaller problems -> find solution for each small
        problem using the provided documents -> generate a final concise solution for the original problem)

        """

        # Downliad and index/embed the documents
        self.index = download_and_index_documents(urls)
        self.small_problems = self.break_down_problem()
        self.solutions = self.brainstorm_all_problems()
        big_solution = self.summarize_solution()

        return big_solution
